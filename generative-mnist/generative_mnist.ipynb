{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian generative models for handwritten digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the 1-NN classifier yielded a 3.09% test error rate on the MNIST data set of handwritten digits. We will now see that a Gaussian generative model does almost as well, while being significantly faster and more compact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up notebook and load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by importing the required packages and data. For this notebook we will be using the *entire* `MNIST` dataset. The code below defines some helper functions that will load `MNIST` onto your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import gzip, os\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# Invokes download() if necessary, then reads in images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz\n",
      "Downloading train-labels-idx1-ubyte.gz\n",
      "Downloading t10k-images-idx3-ubyte.gz\n",
      "Downloading t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **displaychar** shows a single MNIST digit. To do this, it first has to reshape the 784-dimensional vector into a 28x28 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaychar(image):\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "displaychar(train_data[58])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set consists of 60,000 images. Thus `train_data` should be a 60000x784 array while `train_labels` should be 60000x1. Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         54, 227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60,\n",
       "        224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252,\n",
       "        252, 252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253,\n",
       "        253, 190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252,\n",
       "        179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,\n",
       "         84,   0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,\n",
       "         28,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,\n",
       "          0,   0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,\n",
       "          0,   0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85,\n",
       "        178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252,\n",
       "        252, 252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252,\n",
       "        233, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,\n",
       "         37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(train_data[1],(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, counts =np.unique(train_labels, return_counts=True)\n",
    "labels, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 784)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = train_labels==1\n",
    "train_data[condition].shape\n",
    "len(np.mean(train_data[condition,:], axis=0))\n",
    "covmat_1=np.cov(train_data[condition,:],rowvar=0)\n",
    "covmat_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit a Gaussian generative model to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"magenta\">For you to do:</font>** Define a function, **fit_generative_model**, that takes as input a training set (data `x` and labels `y`) and fits a Gaussian generative model to it. It should return the parameters of this generative model; for each label `j = 0,1,...,9`, we have:\n",
    "* `pi[j]`: the frequency of that label\n",
    "* `mu[j]`: the 784-dimensional mean vector\n",
    "* `sigma[j]`: the 784x784 covariance matrix\n",
    "\n",
    "This means that `pi` is 10x1, `mu` is 10x784, and `sigma` is 10x784x784.\n",
    "\n",
    "We have already seen how to fit a Gaussian generative model in the Winery example, but now there is an added ingredient. <font color=\"magenta\">The empirical covariances are very likely to be singular (or close to singular), which means that we won't be able to do calculations with them</font>. Thus it is important to **regularize** these matrices. The standard way of doing this is to add `cI` to them, where `c` is some constant and `I` is the 784-dimensional identity matrix. (To put it another way, we compute the empirical covariances and then increase their diagonal entries by some constant `c`.)\n",
    "\n",
    "This modification is guaranteed to yield covariance matrices that are non-singular, for any `c > 0`, no matter how small. But this doesn't mean that we should make `c` as small as possible. Indeed, `c` is now a parameter, and by setting it appropriately, we can improve the performance of the model. We will study **regularization** in greater detail over the coming weeks.\n",
    "\n",
    "Your routine needs to choose a good setting of `c`. Crucially, this needs to be done using the training set alone. So you might try setting aside part of the training set as a validation set, or using some kind of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_generative_model(x,y,c):\n",
    "    k = 10  # labels 0,1,...,k-1\n",
    "    d = (x.shape)[1]  # number of features\n",
    "    mu = np.zeros((k,d))\n",
    "    sigma = np.zeros((k,d,d))\n",
    "    pi = np.zeros(k)\n",
    "    ###  get counts stats for labels\n",
    "    labels, counts=np.unique(y, return_counts=True)\n",
    "    I=np.identity(d)\n",
    "    for j in labels:\n",
    "        pi[j] = counts[j]/np.sum(counts)\n",
    "        ### index each label in training set \n",
    "        indices = y==j\n",
    "        ### take the mean of each label, returning a mean and covariance matrix\n",
    "        mu[j] = np.mean(x[indices,:], axis=0)\n",
    "        sigma[j] = np.cov(x[indices,:],rowvar=0)+c*I\n",
    "        ### make sure axis =0 and rowvar=0\n",
    "    \n",
    "    # Halt and return parameters\n",
    "    return mu, sigma, pi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's try out your function. In particular, we will use **displaychar** to visualize the means of the Gaussians for the first three digits. You can try the other digits on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu, sigma, pi = fit_generative_model(train_data, train_labels, 1000)\n",
    "displaychar(mu[0])\n",
    "displaychar(mu[1])\n",
    "displaychar(mu[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many errors your model makes on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model makes 489 errors out of 10000\n"
     ]
    }
   ],
   "source": [
    "# Compute log Pr(label|image) for each [test image,label] pair.\n",
    "k=10\n",
    "score = np.zeros((len(test_labels),k))\n",
    "for label in range(0,k):\n",
    "    rv = multivariate_normal(mean=mu[label], cov=sigma[label])\n",
    "    for i in range(0,len(test_labels)):\n",
    "       score[i,label] = np.log(pi[label]) + rv.logpdf(test_data[i,:])\n",
    "predictions = np.argmax(score, axis=1)\n",
    "# Finally, tally up score\n",
    "errors = np.sum(predictions != test_labels)\n",
    "print(\"Your model makes \" + str(errors) + \" errors out of 10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model with c =1 makes 1588 errors out of 10000\n",
      "Your model with c =5 makes 1324 errors out of 10000\n",
      "Your model with c =10 makes 1226 errors out of 10000\n",
      "Your model with c =50 makes 950 errors out of 10000\n",
      "Your model with c =100 makes 806 errors out of 10000\n",
      "Your model with c =500 makes 563 errors out of 10000\n",
      "Your model with c =1000 makes 489 errors out of 10000\n",
      "Your model with c =3000 makes 435 errors out of 10000\n",
      "Your model with c =5000 makes 438 errors out of 10000\n",
      "Your model with c =10000 makes 508 errors out of 10000\n"
     ]
    }
   ],
   "source": [
    "for c in (1,5,10,50,100,500,1000,3000,5000,10000):\n",
    "    mu, sigma, pi = fit_generative_model(train_data, train_labels, c)\n",
    "    k=10\n",
    "    score = np.zeros((len(test_labels),k))\n",
    "    for label in range(0,k):\n",
    "        rv = multivariate_normal(mean=mu[label], cov=sigma[label])\n",
    "        for i in range(0,len(test_labels)):\n",
    "           score[i,label] = np.log(pi[label]) + rv.logpdf(test_data[i,:])\n",
    "    predictions = np.argmax(score, axis=1)\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != test_labels)\n",
    "    print(\"Your model with c =\" + str(c)+ \" makes \" + str(errors) + \" errors out of 10000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You will need to answer variants of these questions as part of this week's assignment*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 1:</font> What happens if you do not regularize the covariance matrices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 2:</font> What happens if you set the value of `c` too high, for instance to one billion? Do you understand why this happens?\n",
    "\n",
    "\n",
    "huge(8000) because of high variance smoothened the prediction/probability distribution together\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 3:</font> What value of c did you end up using? How many errors did your model make on the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">If you have the time</font>: We have talked about using the same regularization constant `c` for all ten classes. What about using a different value of `c` for each class? How would you go about choosing these? Can you get better performance in this way?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
